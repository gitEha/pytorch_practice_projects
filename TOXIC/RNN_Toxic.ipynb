{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from process_data import process_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mã»ts maha kangelste ees. ja nii on.\n",
      "0\n",
      "Number of 0: 122\n",
      "Number of 1: 378\n",
      "Mean lengths of comments: 33.038\n",
      "Mean lengths of comments with the last 25 longest comments removed: 24.76421052631579\n"
     ]
    }
   ],
   "source": [
    "X, y = process_document()\n",
    "print(X[0])\n",
    "print(y[0])\n",
    "X_val = X[500:600]\n",
    "y_val = y[500:600]\n",
    "\n",
    "X = X[:500]\n",
    "y = y[:500]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of 0: {}\".format(y.count(0)))\n",
    "print(\"Number of 1: {}\".format(y.count(1)))\n",
    "from statistics import mean\n",
    "lengths = [len(x_ex.split(' ')) for x_ex in X]\n",
    "lengths.sort()\n",
    "print(\"Mean lengths of comments: {}\".format(mean(lengths)))\n",
    "print(\"Mean lengths of comments with the last 25 longest comments removed: {}\"\n",
    "      .format(mean(lengths[:-25])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab:  7587\n",
      "mã»ts maha kangelste ees. ja nii on.\n",
      "[[1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] Length: 30\n"
     ]
    }
   ],
   "source": [
    "class InputProcessor():\n",
    "    def __init__(self, X_data, vocab_size=10000, comment_length=30):        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.comment_length = comment_length\n",
    "        self.word_to_ix = {}\n",
    "        \n",
    "        #Initialize word_to_ix\n",
    "        self.add_word_to_ix(\"0\")\n",
    "        for comment in X_data:\n",
    "            for word in comment.split(' '):        \n",
    "                self.add_word_to_ix(word)\n",
    "        \n",
    "        \n",
    "    def add_word_to_ix(self, word):\n",
    "        if(word not in self.word_to_ix):\n",
    "            if len(self.word_to_ix) >= self.vocab_size:\n",
    "                self.word_to_ix[word] = self.vocab_size\n",
    "            else:\n",
    "                self.word_to_ix[word] = len(self.word_to_ix)\n",
    "                \n",
    "    def preprocess_input(self, sentences_to_process):\n",
    "        processed_sentences = []\n",
    "\n",
    "        for num, sentence in enumerate(sentences_to_process):\n",
    "            processed_sentences.append([])\n",
    "            sentence = sentence.split(' ')\n",
    "            # Crop sentence or add zero padding\n",
    "            if len(sentence) >= self.comment_length:\n",
    "                sentence = sentence[:self.comment_length]\n",
    "            else:\n",
    "                new_sentence = []\n",
    "                for i in range(self.comment_length):\n",
    "                    if i > len(sentence) - 1:\n",
    "                        new_sentence.append(\"0\")\n",
    "                    else:\n",
    "                        new_sentence.append(sentence[i])\n",
    "                sentence = new_sentence\n",
    "\n",
    "            for word in sentence:\n",
    "                if word in self.word_to_ix:\n",
    "                    processed_sentences[num].append(self.word_to_ix[word])\n",
    "                else:\n",
    "                    self.add_word_to_ix(word)\n",
    "                    processed_sentences[num].append(self.word_to_ix[word])\n",
    "                    \n",
    "        return processed_sentences\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_mini_batches(input_X, input_y, batch_size):\n",
    "        batched_X = []\n",
    "        batched_y = []\n",
    "        for i in range(int(len(input_X) / batch_size) + 1):\n",
    "            batched_X.append(input_X[i*batch_size:i*batch_size + batch_size])\n",
    "            batched_y.append(input_y[i*batch_size:i*batch_size + batch_size])\n",
    "            \n",
    "        return (batched_X, batched_y)\n",
    "        \n",
    "InputProc = InputProcessor(X)\n",
    "\n",
    "print('Total words in vocab: ', len(InputProc.word_to_ix))            \n",
    "test_x = InputProc.preprocess_input([X[0]])\n",
    "print(X[0])\n",
    "print(test_x, 'Length: ' + str(len(test_x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_vocab_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_vocab_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        #self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        #self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        #self.hidden = self.init_hidden()    \n",
    "\n",
    "    def forward(self, input_sentence):\n",
    "        batch_size = input_sentence.size(0)\n",
    "        input_sentence = input_sentence.t()\n",
    "        #print('  input', input_sentence.size())\n",
    "        \n",
    "        embedded = self.embedding(input_sentence)\n",
    "        #print('  embedded', embedded.size())\n",
    "        \n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        #print(' gru hidden output', hidden.size())\n",
    "        #print(' gru output', output.size())\n",
    "        \n",
    "        fc_output = self.fc(hidden)\n",
    "        #print(\"  fc output\", fc_output.size())\n",
    "        \n",
    "        outputs = F.softmax(fc_output, dim=2)\n",
    "        return outputs\n",
    "        \n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        return autograd.Variable(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "[1, 2, 3, 4, 5, 6, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "in torch.Size([500, 30]) out torch.Size([1, 500, 2])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "HIDDEN_SIZE = 32\n",
    "\n",
    "model = RNNClassifier(vocab_size, HIDDEN_SIZE, 2)\n",
    "#loss_function = nn.NLLLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "#print(X)\n",
    "inputs = InputProc.preprocess_input(X)\n",
    "print(len(inputs))\n",
    "print(inputs[0])\n",
    "\n",
    "inp = autograd.Variable(torch.LongTensor(inputs))\n",
    "out = model(inp)\n",
    "print(\"in\", inp.size(), \"out\", out.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.6536\n",
      " 0.3464\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "torch.Size([1, 500, 2])\n",
      "torch.Size([500, 2])\n",
      "Variable containing:\n",
      " 0.6536\n",
      " 0.3464\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out[0][0])\n",
    "print(out.size())\n",
    "\n",
    "out = out.view(out.size()[1], out.size()[2])\n",
    "\n",
    "print(out.size())\n",
    "print(out[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "batched_X, batched_y = InputProc.create_mini_batches(X, y, BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "def train_model(input_X, input_y, model, optimizer, criterion, InpPrep, epochs=5):\n",
    "    for epoch in range(epochs): \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for batch_num, (x, y) in enumerate(zip(input_X, input_y)):                \n",
    "            model.zero_grad()\n",
    "            \n",
    "            x = InpPrep.preprocess_input(x)            \n",
    "            predicted = model(autograd.Variable(torch.LongTensor(x)))\n",
    "            predicted = predicted.view(predicted.size()[1], predicted.size()[2])\n",
    "            \n",
    "            loss = criterion(predicted, autograd.Variable(torch.LongTensor(y)))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "            #_, preds = torch.max(predicted.data, 1)\n",
    "            running_loss += loss.data[0]\n",
    "            \n",
    "            print(loss)\n",
    "            #running_corrects += torch.sum(preds == autograd.Variable(torch.LongTensor(y)).data)\n",
    "            \n",
    "#             if batch_num % 3 == 0:\n",
    "#                 print('Epoch {}: batch {}/{} loss: {}, acc: {}'.\n",
    "#                       format(epoch, batch_num, len(input_X), running_loss / 1,\n",
    "#                              running_corrects / 1\n",
    "#                             ))\n",
    "\n",
    "        print(\"Epoch loss: {}, single: {}\".format(running_loss, running_loss / BATCH_SIZE))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.3997\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3758\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3758\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch loss: 5.411207795143127, single: 0.16910024359822273\n",
      "Variable containing:\n",
      " 0.3996\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3758\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3758\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3445\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.3133\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Epoch loss: 5.4110985696315765, single: 0.16909683030098677\n"
     ]
    }
   ],
   "source": [
    "model = train_model(batched_X, batched_y, model, optimizer, criterion, InputProc, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 2])\n",
      "Traning accuracy: 0.974\n"
     ]
    }
   ],
   "source": [
    "training_preds = model(inp)\n",
    "training_preds = training_preds.view(training_preds.size()[1], training_preds.size()[2])\n",
    "\n",
    "print(training_preds.size())\n",
    "_, preds = torch.max(training_preds.data, 1)\n",
    "\n",
    "summed = np.sum(preds.numpy() == y)\n",
    "print('Traning accuracy: {}'.format(summed / len(training_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "['ammun', 'on', 'ilmselge,', 'siililegi', 'selge,', 'et', 'eesti', 'vajab', 'otse', 'valitavat', 'presidenti.', 'presidendivalimistel', 'oleks', 'mingigi', 'mãµte,', 'kui', 'seda', 'teeks', 'rahavas.', 'ja', 'meie', 'lã¤hinaabruses', 'on', 'riigid,', 'kus', 'presidendil', 'pole', 'suuremat', 'vãµimu', 'kui']\n",
      "[7587, 15, 7588, 7589, 7013, 28, 60, 3145, 80, 7590, 7591, 7592, 64, 3547, 6368, 34, 438, 7593, 7594, 5, 401, 7595, 15, 7596, 897, 7597, 181, 7598, 1549, 34]\n"
     ]
    }
   ],
   "source": [
    "print(len(X_val))\n",
    "inputs_val = InputProc.preprocess_input(X_val)\n",
    "print(X_val[0].split(' ')[:30])\n",
    "print(inputs_val[0])\n",
    "inp_val = autograd.Variable(torch.LongTensor(inputs_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model(inp_val)\n",
    "val_predictions = val_predictions.view(val_predictions.size()[1], val_predictions.size()[2])\n",
    "print(val_preds.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1]\n",
      "1\n",
      "Validation accuracy: 0.64\n"
     ]
    }
   ],
   "source": [
    "print(y_val[0:5])\n",
    "_, val_preds = torch.max(val_predictions.data, 1)\n",
    "print(val_preds[0])\n",
    "\n",
    "summed_val = np.sum(val_preds.numpy() == y_val)\n",
    "print('Validation accuracy: {}'.format(summed_val / len(val_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
